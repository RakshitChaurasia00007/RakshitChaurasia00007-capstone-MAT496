{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöó Car Knowledge Assistant\n",
        "\n",
        "## Overview\n",
        "\n",
        "This automotive knowledge assistant uses AI-powered web search with a **3-expert verification system** to provide reliable information about:\n",
        "- **Maintenance & Repairs**: Service schedules, common issues, troubleshooting\n",
        "- **Interior Customization**: Upgrades, modifications, accessories\n",
        "- **Features & Controls**: How-to guides, feature explanations\n",
        "- **Manual Information**: Owner's manual details, specifications\n",
        "- **DIY Guides**: Step-by-step repair and maintenance tutorials\n",
        "\n",
        "### How It Works (Unique 3-Expert System)\n",
        "\n",
        "1. **Expert 1 (Primary Mechanic)**: Researches and provides initial answer\n",
        "2. **Expert 2 (Verification Specialist)**: Cross-checks Expert 1's information\n",
        "3. **Expert 3 (Conflict Resolver)**: Reviews both experts and resolves any conflicts\n",
        "4. **Beautiful Dashboard**: Results displayed with verification status\n",
        "\n",
        "---\n",
        "\n",
        "**‚ú® Colab-Optimized**: Works perfectly in Google Colab! Verified information you can trust!"
      ],
      "metadata": {
        "id": "9X0IByH4C3mv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "ILBemFvJC9aD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH7PLxWqCaRd"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_openai langchain_community langchain_core tavily-python langchain-tavily wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup API Keys"
      ],
      "metadata": {
        "id": "PFTPoO0eDKBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "bZZs_oAhDLYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0d117b19-e549-482b-e1c6-43a3a24aa780"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1265853882.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TAVILY_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1265853882.py\u001b[0m in \u001b[0;36m_set_env\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ],
      "metadata": {
        "id": "rpPL3NraDTO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai\n"
      ],
      "metadata": {
        "id": "E90SgBg8DUeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python\n"
      ],
      "metadata": {
        "id": "h6gmHvxODYqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community\n"
      ],
      "metadata": {
        "id": "c5LNC6v-Dapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, get_buffer_string\n",
        "from tavily import TavilyClient\n",
        "from langchain_community.document_loaders import WikipediaLoader\n",
        "from IPython.display import display, HTML\n",
        "import operator\n"
      ],
      "metadata": {
        "id": "Yd2B-eaNDgTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Expert System Models"
      ],
      "metadata": {
        "id": "9UdIcrMxENLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CarExpert(BaseModel):\n",
        "    \"\"\"Automotive expert\"\"\"\n",
        "    name: str = Field(description=\"Name of the automotive expert\")\n",
        "    role: str = Field(description=\"Expert role (Primary Mechanic / Verification Specialist / Conflict Resolver)\")\n",
        "    specialty: str = Field(description=\"Area of automotive expertise\")\n",
        "\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return f\"Name: {self.name}\\nRole: {self.role}\\nSpecialty: {self.specialty}\\n\"\n",
        "\n",
        "class ExpertResponse(BaseModel):\n",
        "    \"\"\"Expert's response with confidence and sources\"\"\"\n",
        "    expert_name: str = Field(description=\"Name of the expert\")\n",
        "    response: str = Field(description=\"Detailed response\")\n",
        "    confidence: str = Field(description=\"Confidence level: High/Medium/Low\")\n",
        "    sources: List[str] = Field(description=\"List of source URLs\")\n",
        "    issues_found: List[str] = Field(default=[], description=\"Issues or conflicts found (for verification)\")\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    search_query: str = Field(description=\"Automotive search query\")\n",
        "\n",
        "class VerificationState(TypedDict):\n",
        "    car_topic: str\n",
        "    expert1_response: ExpertResponse\n",
        "    expert2_response: ExpertResponse\n",
        "    expert3_response: ExpertResponse\n",
        "    search_context: list\n",
        "    final_answer: str\n",
        "\n",
        "print(\"‚úÖ Expert system models defined!\")"
      ],
      "metadata": {
        "id": "BUA0B2-wEQny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MUST be run BEFORE any expert functions are defined!\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Initialize Tavily Search Client\n",
        "tavily = TavilyClient(api_key=\"YOUR_TAVILY_API_KEY\")  # Or use environment variable\n",
        "\n",
        "print(\"‚úÖ LLM and Tavily initialized!\")\n"
      ],
      "metadata": {
        "id": "9lrpyyMDEad6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Search Functions"
      ],
      "metadata": {
        "id": "k9JBr5PGEd-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_automotive_info(query: str) -> str:\n",
        "    \"\"\"Search for automotive information\"\"\"\n",
        "    print(f\"      üîç Searching for: {query}\")\n",
        "\n",
        "    try:\n",
        "        results = tavily.search(query=query)  # Tavily returns a dict\n",
        "\n",
        "        # Standardized extraction\n",
        "        if isinstance(results, dict):\n",
        "            search_docs = results.get(\"results\", [])\n",
        "        elif isinstance(results, list):\n",
        "            search_docs = results\n",
        "        else:\n",
        "            search_docs = []\n",
        "\n",
        "        if search_docs:\n",
        "            formatted_docs = \"\\n\\n---\\n\\n\".join([\n",
        "                f'<Source url=\"{doc.get(\"url\", \"N/A\")}\"/>\\n'\n",
        "                f'{str(doc.get(\"content\", doc.get(\"snippet\", \"\")))[:500]}...\\n</Source>'\n",
        "                for doc in search_docs[:3] if isinstance(doc, dict)\n",
        "            ])\n",
        "            print(f\"      ‚úÖ Found {len(search_docs)} sources\")\n",
        "            return formatted_docs\n",
        "\n",
        "        else:\n",
        "            print(\"      ‚ö†Ô∏è No results found\")\n",
        "            return \"No search results found.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ùå Search error: {e}\")\n",
        "        return f\"Search error: {str(e)}\"\n",
        "\n",
        "print(\"‚úÖ Search functions ready!\")\n"
      ],
      "metadata": {
        "id": "p0zabBBEEfNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expert 1: Primary Mechanic (Information Provider)"
      ],
      "metadata": {
        "id": "SVkDayc3ElFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expert1_instructions = \"\"\"You are a PRIMARY AUTOMOTIVE MECHANIC providing initial information.\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "Research Context:\n",
        "{context}\n",
        "\n",
        "Your job:\n",
        "1. Provide detailed, accurate automotive information\n",
        "2. Base all answers on the provided sources\n",
        "3. Include:\n",
        "   - Step-by-step instructions (if applicable)\n",
        "   - Safety warnings\n",
        "   - Required tools/parts\n",
        "   - Common mistakes to avoid\n",
        "4. Cite sources using [1], [2], etc.\n",
        "5. Rate your confidence: High/Medium/Low\n",
        "\n",
        "Be thorough and practical. This is the initial answer that will be verified.\n",
        "\"\"\"\n",
        "\n",
        "def expert1_provide_info(state: VerificationState):\n",
        "    \"\"\"Expert 1 provides initial answer\"\"\"\n",
        "    topic = state['car_topic']\n",
        "\n",
        "    print(\"\\nüîß Expert 1 (Primary Mechanic) researching...\")\n",
        "\n",
        "    # Search for information\n",
        "    context = search_automotive_info(topic)\n",
        "\n",
        "    # Generate response\n",
        "    system_message = expert1_instructions.format(topic=topic, context=context)\n",
        "\n",
        "    structured_llm = llm.with_structured_output(ExpertResponse)\n",
        "    response = structured_llm.invoke([\n",
        "        SystemMessage(content=system_message),\n",
        "        HumanMessage(content=f\"Provide comprehensive information about: {topic}\")\n",
        "    ])\n",
        "\n",
        "    print(f\"   ‚úÖ Expert 1 complete (Confidence: {response.confidence})\")\n",
        "\n",
        "    return {\n",
        "        \"expert1_response\": response,\n",
        "        \"search_context\": [context]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Expert 1 (Primary Mechanic) ready!\")\n"
      ],
      "metadata": {
        "id": "pjzMMVSpEmkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expert 2: Verification Specialist (Cross-Checker)"
      ],
      "metadata": {
        "id": "0gVvEpXoErYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expert2_instructions = \"\"\"You are a VERIFICATION SPECIALIST cross-checking automotive information.\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "Expert 1's Answer:\n",
        "{expert1_answer}\n",
        "\n",
        "Additional Research Context:\n",
        "{context}\n",
        "\n",
        "Your job:\n",
        "1. Verify Expert 1's information against sources\n",
        "2. Check for:\n",
        "   - Factual accuracy\n",
        "   - Safety concerns\n",
        "   - Missing critical steps\n",
        "   - Incorrect specifications\n",
        "3. If you find issues, list them clearly\n",
        "4. Provide additional information Expert 1 missed\n",
        "5. Cite your sources [1], [2], etc.\n",
        "6. Rate confidence: High/Medium/Low\n",
        "\n",
        "Be thorough - lives depend on accurate car maintenance!\"\"\"\n",
        "\n",
        "def expert2_verify_info(state: VerificationState):\n",
        "    \"\"\"Expert 2 verifies and cross-checks\"\"\"\n",
        "    topic = state['car_topic']\n",
        "    expert1 = state['expert1_response']\n",
        "\n",
        "    print(\"\\n‚úÖ Expert 2 (Verification Specialist) cross-checking...\")\n",
        "\n",
        "    # Search for verification\n",
        "    verify_query = f\"{topic} verification safety check correct procedure\"\n",
        "    context = search_automotive_info(verify_query)\n",
        "\n",
        "    # Verify response\n",
        "    system_message = expert2_instructions.format(\n",
        "        topic=topic,\n",
        "        expert1_answer=expert1.response,\n",
        "        context=context\n",
        "    )\n",
        "\n",
        "    structured_llm = llm.with_structured_output(ExpertResponse)\n",
        "    response = structured_llm.invoke([\n",
        "        SystemMessage(content=system_message),\n",
        "        HumanMessage(content=f\"Verify and cross-check the information about: {topic}\")\n",
        "    ])\n",
        "\n",
        "    print(f\"   ‚úÖ Expert 2 complete (Confidence: {response.confidence})\")\n",
        "    if response.issues_found:\n",
        "        print(f\"   ‚ö†Ô∏è Issues found: {len(response.issues_found)}\")\n",
        "\n",
        "    return {\n",
        "        \"expert2_response\": response,\n",
        "        \"search_context\": state['search_context'] + [context]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Expert 2 (Verification Specialist) ready!\")"
      ],
      "metadata": {
        "id": "NSIqLvV6Esks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expert 3: Conflict Resolver (Final Authority)"
      ],
      "metadata": {
        "id": "AcZi_Er3Exsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expert3_instructions = \"\"\"You are a SENIOR AUTOMOTIVE EXPERT and CONFLICT RESOLVER.\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "Expert 1's Response (Primary Mechanic):\n",
        "{expert1_answer}\n",
        "Confidence: {expert1_confidence}\n",
        "\n",
        "Expert 2's Verification:\n",
        "{expert2_answer}\n",
        "Issues Found: {expert2_issues}\n",
        "Confidence: {expert2_confidence}\n",
        "\n",
        "All Research Sources:\n",
        "{context}\n",
        "\n",
        "Your job:\n",
        "1. Review both experts' responses\n",
        "2. Resolve any conflicts or discrepancies\n",
        "3. Create the FINAL, AUTHORITATIVE answer\n",
        "4. If conflicts exist, explain which expert is correct and why\n",
        "5. Integrate the best information from both experts\n",
        "6. Add any critical information both missed\n",
        "7. Ensure safety is prioritized\n",
        "8. Provide clear, actionable guidance\n",
        "9. Include all relevant sources\n",
        "\n",
        "Your answer will be the final word - make it comprehensive and accurate!\"\"\"\n",
        "\n",
        "def expert3_resolve_conflicts(state: VerificationState):\n",
        "    \"\"\"Expert 3 resolves conflicts and provides final answer\"\"\"\n",
        "    topic = state['car_topic']\n",
        "    expert1 = state['expert1_response']\n",
        "    expert2 = state['expert2_response']\n",
        "    contexts = state['search_context']\n",
        "\n",
        "    print(\"\\nüèÜ Expert 3 (Conflict Resolver) reviewing...\")\n",
        "\n",
        "    # Compile all context\n",
        "    all_context = \"\\n\\n\".join(contexts)\n",
        "\n",
        "    # Resolve and finalize\n",
        "    system_message = expert3_instructions.format(\n",
        "        topic=topic,\n",
        "        expert1_answer=expert1.response,\n",
        "        expert1_confidence=expert1.confidence,\n",
        "        expert2_answer=expert2.response,\n",
        "        expert2_issues=expert2.issues_found,\n",
        "        expert2_confidence=expert2.confidence,\n",
        "        context=all_context[:3000]  # Limit context\n",
        "    )\n",
        "\n",
        "    structured_llm = llm.with_structured_output(ExpertResponse)\n",
        "    response = structured_llm.invoke([\n",
        "        SystemMessage(content=system_message),\n",
        "        HumanMessage(content=f\"Provide the final, authoritative answer about: {topic}\")\n",
        "    ])\n",
        "\n",
        "    print(f\"   ‚úÖ Expert 3 complete (Final Confidence: {response.confidence})\")\n",
        "\n",
        "    return {\n",
        "        \"expert3_response\": response,\n",
        "        \"final_answer\": response.response\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Expert 3 (Conflict Resolver) ready!\")"
      ],
      "metadata": {
        "id": "d-0B7TyaEyzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Verification Graph"
      ],
      "metadata": {
        "id": "nJK4apWSE42A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the 3-expert verification workflow\n",
        "workflow = StateGraph(VerificationState)\n",
        "\n",
        "# Add expert nodes\n",
        "workflow.add_node(\"expert1_provide\", expert1_provide_info)\n",
        "workflow.add_node(\"expert2_verify\", expert2_verify_info)\n",
        "workflow.add_node(\"expert3_resolve\", expert3_resolve_conflicts)\n",
        "\n",
        "# Define workflow: Expert 1 ‚Üí Expert 2 ‚Üí Expert 3\n",
        "workflow.add_edge(START, \"expert1_provide\")\n",
        "workflow.add_edge(\"expert1_provide\", \"expert2_verify\")\n",
        "workflow.add_edge(\"expert2_verify\", \"expert3_resolve\")\n",
        "workflow.add_edge(\"expert3_resolve\", END)\n",
        "\n",
        "# Compile\n",
        "verification_graph = workflow.compile()\n",
        "\n",
        "print(\"‚úÖ 3-Expert Verification System ready!\")\n",
        "print(\"   Flow: Primary Mechanic ‚Üí Verification ‚Üí Conflict Resolution\")"
      ],
      "metadata": {
        "id": "Iuf-eby9E53A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé® Beautiful Dashboard Display"
      ],
      "metadata": {
        "id": "jEMUN_aFGZk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìù Markdown Display Function for Car Knowledge Assistant\n",
        "# Copy and paste this cell to replace the HTML dashboard\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def create_car_dashboard(topic, expert1, expert2, expert3):\n",
        "    \"\"\"\n",
        "    Creates clean Markdown display showing 3-expert verification process\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine overall status\n",
        "    has_conflicts = len(expert2.issues_found) > 0\n",
        "    status = \"‚ö†Ô∏è CONFLICTS RESOLVED\" if has_conflicts else \"‚úÖ VERIFIED\"\n",
        "\n",
        "    # Build markdown report\n",
        "    markdown_report = f\"\"\"\n",
        "# üöó Car Knowledge Assistant\n",
        "\n",
        "## {topic}\n",
        "\n",
        "**Status:** {status}\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Expert 1: Primary Mechanic\n",
        "\n",
        "**Confidence:** {expert1.confidence} {'üü¢' if expert1.confidence == 'High' else 'üü†' if expert1.confidence == 'Medium' else 'üî¥'}\n",
        "\n",
        "{expert1.response}\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Expert 2: Verification Specialist\n",
        "\n",
        "**Confidence:** {expert2.confidence} {'üü¢' if expert2.confidence == 'High' else 'üü†' if expert2.confidence == 'Medium' else 'üî¥'}\n",
        "\n",
        "{expert2.response}\n",
        "\n",
        "{'### ‚ö†Ô∏è Issues Found:' if expert2.issues_found else ''}\n",
        "{''.join([f'- {issue}' + chr(10) for issue in expert2.issues_found])}\n",
        "\n",
        "---\n",
        "\n",
        "## üèÜ Expert 3: Final Authoritative Answer\n",
        "\n",
        "**Confidence:** {expert3.confidence} {'üü¢' if expert3.confidence == 'High' else 'üü†' if expert3.confidence == 'Medium' else 'üî¥'}\n",
        "\n",
        "{expert3.response}\n",
        "\n",
        "{'### üìö Sources:' if expert3.sources else ''}\n",
        "{''.join([f'- {source}' + chr(10) for source in expert3.sources])}\n",
        "\n",
        "---\n",
        "\n",
        "> **‚ö†Ô∏è SAFETY WARNING:** Always consult your vehicle's owner manual and consider professional help for complex repairs. Improper maintenance can be dangerous.\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    display(Markdown(markdown_report))\n",
        "\n",
        "print(\"‚úÖ Markdown display function ready!\")\n"
      ],
      "metadata": {
        "id": "REaUrU25GrRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöó Ask Car Question"
      ],
      "metadata": {
        "id": "LnMXZQa5G3MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your car question\n",
        "car_question = \"Should I buy a Sports car  ?\"\n",
        "\n",
        "print(f\"üöó Question: {car_question}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "libSLd84G4od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run 3-Expert Verification Process"
      ],
      "metadata": {
        "id": "2bozZDJyHNM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the verification workflow\n",
        "print(\"\\nüîÑ Starting 3-Expert Verification Process...\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result = verification_graph.invoke({\n",
        "    \"car_topic\": car_question,\n",
        "    \"search_context\": []\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ Verification Complete!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "AFXiXoMvHQiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Results in Beautiful Dashboard"
      ],
      "metadata": {
        "id": "o3ATbQcyHVcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the dashboard\n",
        "create_car_dashboard(\n",
        "    car_question,\n",
        "    result['expert1_response'],\n",
        "    result['expert2_response'],\n",
        "    result['expert3_response']\n",
        ")\n",
        "\n",
        "print(\"\\nüéâ Scroll up to see your verified car maintenance guide!\")"
      ],
      "metadata": {
        "id": "ULgCldENHWqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "##  Features\n",
        "\n",
        "‚úÖ **3-Expert Verification System**: Information ‚Üí Verification ‚Üí Conflict Resolution  \n",
        "‚úÖ **Real Web Search**: Current automotive information  \n",
        "‚úÖ **Conflict Detection**: Identifies discrepancies between experts  \n",
        "‚úÖ **Confidence Ratings**: Know how reliable the information is  \n",
        "‚úÖ **Source Citations**: All answers backed by sources  \n",
        "‚úÖ **Beautiful Dashboard**: Color-coded by verification status  \n",
        "‚úÖ **Safety Warnings**: Always prioritizes safety  \n",
        "\n",
        "##  Covers:\n",
        "\n",
        "-  Maintenance & Repairs\n",
        "-  Interior Customization  \n",
        "-  Features & Controls\n",
        "-  Owner's Manual Info\n",
        "-  DIY Repair Guides\n",
        "\n",
        "---\n",
        "\n",
        "*Car Knowledge Assistant - Triple-verified automotive information you can trust!* üöó‚ú®"
      ],
      "metadata": {
        "id": "zFCra9iGHquD"
      }
    }
  ]
}